{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level Language Model\n",
    "### (CS231n: lecutre 8 - 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 0, 0, 1]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab = [\"h\", \"e\", \"l\", \"o\"]\n",
    "sequence = \"hello\"\n",
    "\n",
    "# tokenization(character-level)\n",
    "seq = list(sequence)                            # 문자열을 개별 문자로 분리\n",
    "\n",
    "# one-hot encoding\n",
    "seq_encoding = []\n",
    "for i in range(len(seq)):\n",
    "    encoding = [0] * len(vocab)                 # 리스트 내부를 모두 0으로 채우기\n",
    "    for index, value in enumerate(vocab):       # 인덱스와 인덱스에 해당하는 리스트 요소 가져오기\n",
    "        if(seq[i] == value):\n",
    "            encoding[index] = 1\n",
    "            seq_encoding.append(encoding)\n",
    "\n",
    "seq_encoding = torch.tensor(seq_encoding)       # 리스트를 tensor로 변환\n",
    "print(seq_encoding)\n",
    "print(seq_encoding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# weight matrix 초기화\n",
    "W_hh = np.random.randn(3, 3)            # 크기가 3x3인 난수 행렬 생성 (정규분포)\n",
    "W_hh = torch.from_numpy(W_hh)           # numpy를 tensor로 변환\n",
    "print(W_hh.shape)\n",
    "\n",
    "W_xh = np.random.randn(4, 3)\n",
    "W_xh = torch.from_numpy(W_xh)\n",
    "print(W_xh.shape)\n",
    "\n",
    "W_hy = np.random.randn(3, 4)\n",
    "W_hy = torch.from_numpy(W_hy)\n",
    "print(W_hy.shape)\n",
    "\n",
    "# 초기 hidden state 값을 0으로 설정\n",
    "h_0 = torch.zeros(3, 3)                 # tensor([[0., 0., 0.],\n",
    "                                              #   [0., 0., 0.],\n",
    "                                              #   [0., 0., 0.]])\n",
    "print(h_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: double != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# <주의>\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# * 연산자는 요소별 곱셈을 수행함\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# torch.matmul() or @ 연산자가 행렬 곱셈을 수행함\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_hh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(W_xh, seq_encoding[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     10\u001b[0m hidden_state\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: double != float"
     ]
    }
   ],
   "source": [
    "# <주의>\n",
    "# * 연산자는 요소별 곱셈을 수행함\n",
    "# torch.matmul() or @ 연산자가 행렬 곱셈을 수행함\n",
    "\n",
    "hidden_state = torch.matmul(W_hh, h_0)\n",
    "\n",
    "input = torch.matmul(W_xh, seq_encoding[0])\n",
    "\n",
    "\n",
    "hidden_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
